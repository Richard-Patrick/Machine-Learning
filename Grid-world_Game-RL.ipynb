{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "691ccb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395e9eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ff277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    \n",
    "    def __init__(self, epsilon=0.9, episodes=100, max_steps=100, alpha=0.085, gamma=0.9):\n",
    "        self.epsilon = epsilon      \n",
    "        self.num_episodes = episodes\n",
    "        self.max_steps = max_steps\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.state = None\n",
    "        self.reward = 0\n",
    "        self.state_space = 5*4\n",
    "        self.action_space = 4\n",
    "        self.Q = np.zeros((self.state_space, self.action_space), np.float32)\n",
    "\n",
    "    def next_action(self, state, exploitation=False):       \n",
    "        if np.random.uniform(0,1) < self.epsilon and exploitation == False: \n",
    "            action = np.random.randint(self.action_space) \n",
    "        else: \n",
    "            action = np.argmax(self.Q[state, :])          \n",
    "        return action \n",
    "  \n",
    "    def next_state(self, state, action):\n",
    "        x = int(state/5)\n",
    "        y = state%5\n",
    "    \n",
    "        old_x,old_y = x,y\n",
    "            \n",
    "        if (action == 0):\n",
    "            if (x != 0):\n",
    "                x = x-1\n",
    "        \n",
    "        elif (action == 1):\n",
    "            if (y != 4):\n",
    "                y = y+1\n",
    "        \n",
    "        elif (action == 2):\n",
    "            if (x != 3):\n",
    "                x = x+1      \n",
    "        \n",
    "        elif (action == 3):\n",
    "            if (y != 0):\n",
    "                y = y-1\n",
    "                                        \n",
    "        self.state = x*5+y\n",
    "        \n",
    "        if ((x,y) == (old_x,old_y)):\n",
    "            reward = -1\n",
    "        elif ((x,y) == (0,0)):\n",
    "            reward = 10\n",
    "        elif ((x,y) == (1,3)):\n",
    "            reward = -5\n",
    "        else:\n",
    "            reward = 0\n",
    "\n",
    "        if ((old_x,old_y) == (1,3)):\n",
    "            self.state_visualization[old_x][old_y] = \"F\"\n",
    "        else:\n",
    "            self.state_visualization[old_x][old_y] = \"-\"\n",
    "        self.state_visualization[x][y] = \"S\"\n",
    "\n",
    "        return self.state, reward\n",
    "\n",
    "    def updateQ(self, current_state, next_state, reward, current_action, next_action):\n",
    "        Q = self.Q[current_state][current_action] \n",
    "        Qnext = (reward + self.gamma * self.Q[next_state][next_action])\n",
    "        self.Q[current_state][current_action] = (1-self.alpha)*Q + self.alpha*Qnext\n",
    "        \n",
    "    def reset(self):\n",
    "        self.state_visualization = np.array([['G', '-' ,'-' ,'-', '-'],\n",
    "                              ['-', '-' ,'-' ,'F', '-'],\n",
    "                              ['-', '-' ,'-' ,'-', '-'],\n",
    "                              ['-', '-' ,'-' ,'-', 'S']])\n",
    "        self.state = 19\n",
    "        return self.state\n",
    "        \n",
    "    def is_goal_state(self):\n",
    "        return self.state == 0\n",
    "    \n",
    "    def actions_map(self, i):\n",
    "        if (i==0):\n",
    "            return \"Up\"\n",
    "        elif (i==1):\n",
    "            return \"Right\"\n",
    "        elif (i==2):\n",
    "            return \"Down\"\n",
    "        elif (i==3):\n",
    "            return \"Left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6c4daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Environment(episodes=300, max_steps=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5b0685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(environment.num_episodes): \n",
    "    t = 0\n",
    "    \n",
    "    current_state = environment.reset()\n",
    "\n",
    "    while t < environment.max_steps and not environment.is_goal_state(): \n",
    "        \n",
    "        current_action = environment.next_action(current_state) \n",
    "        \n",
    "        next_state, reward = environment.next_state(current_state, current_action)\n",
    "\n",
    "        next_action = environment.next_action(next_state, exploitation=True)\n",
    "        \n",
    "        environment.updateQ(current_state, next_state, reward, current_action, next_action)\n",
    "  \n",
    "        current_state = next_state\n",
    "          \n",
    "        t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cdc65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploitation = True\n",
    "current_state = environment.reset()\n",
    "current_action = environment.next_action(current_state, exploitation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a7eef7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['G' '-' '-' '-' '-']\n",
      " ['-' '-' '-' 'F' '-']\n",
      " ['-' '-' '-' '-' 'S']\n",
      " ['-' '-' '-' '-' '-']] ,    Up , reward: 0 \n",
      "\n",
      "\n",
      "[['G' '-' '-' '-' '-']\n",
      " ['-' '-' '-' 'F' 'S']\n",
      " ['-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-']] ,    Up , reward: 0 \n",
      "\n",
      "\n",
      "[['G' '-' '-' '-' 'S']\n",
      " ['-' '-' '-' 'F' '-']\n",
      " ['-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-']] ,    Up , reward: 0 \n",
      "\n",
      "\n",
      "[['G' '-' '-' 'S' '-']\n",
      " ['-' '-' '-' 'F' '-']\n",
      " ['-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-']] ,    Left , reward: 0 \n",
      "\n",
      "\n",
      "[['G' '-' 'S' '-' '-']\n",
      " ['-' '-' '-' 'F' '-']\n",
      " ['-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-']] ,    Left , reward: 0 \n",
      "\n",
      "\n",
      "[['G' 'S' '-' '-' '-']\n",
      " ['-' '-' '-' 'F' '-']\n",
      " ['-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-']] ,    Left , reward: 0 \n",
      "\n",
      "\n",
      "[['S' '-' '-' '-' '-']\n",
      " ['-' '-' '-' 'F' '-']\n",
      " ['-' '-' '-' '-' '-']\n",
      " ['-' '-' '-' '-' '-']] ,    Left , reward: 10 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while t < environment.max_steps and not environment.is_goal_state():\n",
    "\n",
    "    next_state, reward = environment.next_state(current_state, current_action)\n",
    "\n",
    "    print(environment.state_visualization, \",   \", \n",
    "          environment.actions_map(current_action), \n",
    "          \", reward:\", reward, \"\\n\\n\")\n",
    "\n",
    "    next_action = environment.next_action(next_state, exploitation)\n",
    "\n",
    "    current_state = next_state\n",
    "    current_action = next_action\n",
    "\n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac92476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3de8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
